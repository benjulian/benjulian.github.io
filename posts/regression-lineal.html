<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fundamentos de la Regresion Lineal</title>
    
    <link rel="stylesheet" href="../style.css"> 
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!-- Mantenemos la combinación original que te gustó -->
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,700;1,400&family=Source+Code+Pro:wght@400;700&display=swap" rel="stylesheet">
    
    <!-- Hoja de estilos de Prism.js (tema oscuro "Tomorrow Night") -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <main class="post-full">
        <header class="post-header">
            <h1>Fundamentos de la Regresion Lineal</h1>
            <p class="post-meta">15 of October, 2025</p>
        </header>

        <article class="post-content">

          <h2><strong>El Fundamento de la Predicción: Una Introducción a la Regresión Lineal desde los Primeros Principios</strong></h2>

          <p>En el estudio de cualquier fenómeno, nuestro punto de partida es casi siempre el mismo: la observación de los datos. Imaginemos que hemos recolectado un conjunto de mediciones, donde para cada observación disponemos de un conjunto de variables de entrada y un valor de salida correspondiente. Al visualizar estos datos, por ejemplo, en un simple gráfico de dispersión, podríamos notar una tendencia reveladora: los puntos parecen agruparse en torno a una línea recta.</p>

          <p>Esta observación visual, aunque simple, es profundamente significativa. Sugiere que podría existir una relación funcional subyacente que conecta nuestras entradas con nuestras salidas. Ante esta evidencia, nos planteamos una pregunta fundamental: ¿cuál es la estructura matemática más simple y fundamental que podría describir esta tendencia? La respuesta, por supuesto, es la ecuación de una recta.</p>

          <h3><strong>La Hipótesis de Linealidad</strong></h3>

            <p>Esto nos lleva a formular nuestra hipótesis central: <strong>asumimos que la relación entre las variables de entrada y las de salida es de naturaleza lineal</strong>. Este es el nacimiento conceptual del modelo de <strong>Regresión Lineal</strong>.</p> 
            
            <p>No pretendemos que los datos se ajusten perfectamente a una línea; el mundo real es inherentemente ruidoso y complejo. En cambio, nuestro objetivo es encontrar la línea "óptima" que mejor represente la tendencia general contenida en los datos, minimizando la distancia promedio entre la línea y cada punto de datos.</p>
  
            <p>En un caso simple con una sola variable de entrada, esta idea se materializa en la conocida ecuación \(y = mx + b\). Sin embargo, en el dominio de la inteligencia artificial, rara vez trabajamos con una única variable de entrada. Generalmente, cada muestra de nuestros datos está definida por un conjunto de \(b\) características o <em>features</em>. Por lo tanto, debemos generalizar nuestra noción de "línea" desde un plano bidimensional a un espacio de alta dimensionalidad. En este nuevo contexto, nuestra "línea" se convierte en un <strong>hiperplano</strong>.</p>
  
            <p>La formalización matemática de esta transformación lineal, que constituye el corazón de nuestro modelo, se expresa de la siguiente manera:</p>
            
            \[ Z_{ac} = X_{ab}W_{bc} + B_{ac} \]
            
            <p>Aquí, \(X\) representa nuestros datos de entrada, mientras que \(W\) (los pesos) y \(B\) (el sesgo) son los parámetros del modelo que debemos "aprender". El tensor \(Z\) contendrá las predicciones generadas por el modelo.</p>

          <h3><strong>El Objetivo: Aprender a Predecir</strong></h3>
          
            <p>El propósito del "aprendizaje" en este modelo es, precisamente, encontrar los valores numéricos para los tensores \(W\) y \(B\) que hagan que nuestras predicciones, \(Z\), sean lo más cercanas posible a los valores reales observados, que llamaremos \(Y\). Para lograr esto, nos embarcamos en un proceso iterativo conocido como el <strong>Ciclo de Entrenamiento</strong> (<em>Training Cycle</em>). Este ciclo, que exploraremos en detalle a lo largo de este artículo, se compone de cuatro etapas conceptuales:</p>
            
            <ol>
                
                <li><strong>Forward Pass (Paso hacia adelante):</strong> Utilizando una estimación inicial de \(W\) y \(B\), aplicamos la ecuación del modelo a nuestros datos de entrada \(X\) para generar un conjunto de predicciones \(Z\).</li>
                <br>
                <li><strong>Loss Computation (Cálculo de la Périda):</strong> Medimos qué tan erróneas son nuestras predicciones comparando \(Z\) con los valores verdaderos \(Y\). Esta medida de error se cuantifica en un único valor escalar llamado "périda" (<em>loss</em>).</li>
                <br>
                <li><strong>Backward Pass (Paso hacia atrás):</strong> Aquí es donde interviene el cálculo. Determinamos cómo un pequeño cambio en cada uno de los parámetros de \(W\) y \(B\) afectaría la pérdida total. Este proceso nos da los gradientes, que nos indican la dirección en la que debemos ajustar nuestros parámetros para reducir el error.</li>
                <br>
                <li><strong>Optimization (Optimización):</strong> Finalmente, actualizamos los valores de \(W\) y \(B\) moviéndolos ligeramente en la dirección opuesta a sus gradientes, acercándonos un paso más a la configuración óptima que minimiza el error.</li>
            
            </ol>
            
            <p>Este ciclo se repite una y otra vez, refinando progresivamente los parámetros del modelo hasta que nuestras predicciones sean lo más precisas posible.</p>
            
            <p>Antes de sumergirnos en la mecánica de este ciclo, es imperativo establecer un lenguaje común. Nuestro primer paso será definir formalmente las estructuras de datos, o tensores, con las que operaremos, estableciendo las convenciones de notación que nos guiarán a través de este desarrollo matemático.</p>

            <hr>

            <h2><strong>Formalización Matemática: Definiendo los Tensores del Modelo</strong></h2>
            
            <p>Para construir nuestro modelo de Regresión Lineal sobre una base rigurosa, debemos primero definir con precisión los objetos matemáticos que lo componen. En este contexto, trataremos todas nuestras estructuras de datos —entradas, salidas y parámetros— como <strong>tensores</strong>. Un tensor es una generalización de vectores y matrices a un número arbitrario de dimensiones, y nos proporciona un marco robusto para describir las operaciones de nuestro modelo.</p>
            
            <p>Para manipular estos tensores, emplearemos exclusivamente la <strong>notación de Einstein</strong>. Esta convención es a la vez elegante y poderosa: cualquier índice que aparezca repetido en un mismo término implica una suma sobre todos los valores posibles de dicho índice. Por ejemplo, un término como \(X_{ab}W_{bc}\) es una forma compacta de escribir \(\sum_{b} X_{ab}W_{bc}\). Esta notación nos permitirá expresar operaciones complejas, como la multiplicación de matrices, sin la ambigüedad de la notación matricial tradicional, enfocándonos en la interacción entre las dimensiones.</p>
            
            <h3><strong>Los Datos: Entrada y Salida</strong></h3>
            
            <p>Nuestros datos consisten en dos componentes principales: las observaciones de entrada y los valores objetivo correspondientes.</p>
            
            <ul>
                <li><strong>El Tensor de Entrada \(X\):</strong> Este tensor contiene el conjunto completo de nuestras observaciones. Lo definimos como un tensor de rango 2 (una matriz) de dimensiones \(a \times b\):
                    
                    \[ X \in \mathbb{R}^{a \times b} \]
                    
                    Los índices tienen un significado preciso:
                    
                    <br>
                    
                    <ul>
                        <li>El índice \(a\) recorre las <strong>muestras</strong> (<em>samples</em>) de nuestro conjunto de datos, desde \(1\) hasta el número total de observaciones.</li>

                        <br>
                        
                        <li>El índice \(b\) recorre las <strong>características</strong> (<em>features</em>) que describen cada muestra.</li>
                    </ul>

                    <br>
                    
                    Este tensor se veria (de manera general) asi:

                    \[
                    X = \begin{bmatrix}
                        x_{11} & x_{12} & \cdots & x_{1b} \\
                        x_{21} & x_{22} & \cdots & x_{2b} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        x_{a1} & x_{a2} & \cdots & x_{ab}
                    \end{bmatrix}
                    \]
                    
                    Así, un elemento escalar \(X_{ab}\) representa el valor de la \(b\)-ésima característica para la \(a\)-ésima muestra de nuestros datos.
                </li>
                
                <br>
                
                <li><strong>El Tensor Objetivo \(Y\):</strong> Este tensor alberga los valores verdaderos que nuestro modelo aspira a predecir. Al igual que \(X\), es un tensor de rango 2, pero con dimensiones \(a \times c\):
                    
                    \[ Y \in \mathbb{R}^{a \times c} \]
                    
                    El significado de sus índices es el siguiente:

                    <br><br>
                    
                    <ul>
                        <li>El índice \(a\) corresponde directamente al índice de muestras de \(X\), asegurando una alineación perfecta entre cada entrada y su salida esperada.</li>
                        
                        <br>

                        <li>El índice \(c\) recorre las <strong>clases</strong> o variables de salida. En el caso más simple de regresión, \(c\) podría ser 1, pero esta notación nos permite manejar modelos que predicen múltiples valores simultáneamente.</li>
                    </ul>

                    <br>
                    
                    Este tensor se veria (de manera general) asi:

                    \[
                    Y = \begin{bmatrix}
                        y_{11} & y_{12} & \cdots & y_{1c} \\
                        y_{21} & y_{22} & \cdots & y_{2c} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        y_{a1} & y_{a2} & \cdots & y_{ac}
                    \end{bmatrix}
                    \]
                    
                    Un elemento \(Y_{ac}\) es, por tanto, el valor real de la \(c\)-ésima variable de salida para la \(a\)-ésima muestra.
                </li>
            </ul>
            
            <h3><strong>Los Parámetros del Modelo: Pesos y Sesgo</strong></h3>
            
            <p>Los parámetros del modelo son los valores numéricos que no se derivan de los datos, sino que son "aprendidos" durante el proceso de entrenamiento. Son las "perillas" que ajustaremos para minimizar el error de predicción.</p>
            
            <ul>
                <li><strong>El Tensor de Pesos \(W\):</strong> El tensor de pesos \(W\) captura la fuerza y el signo de la relación entre cada característica de entrada y cada clase de salida. Se define como un tensor de rango 2 de dimensiones \(b \times c\):
                    
                    \[ W \in \mathbb{R}^{b \times c} \]
                    
                    La lógica de sus índices es crucial para la conexión entre entrada y salida:
                    
                    <br>
                    
                    <ul>
                        <li>El índice \(b\) se alinea con las \(b\) características del tensor de entrada \(X\).</li>
                        
                        <br>
                        
                        <li>El índice \(c\) se alinea con las \(c\) clases del tensor de salida \(Y\).</li>
                    </ul>

                    <br>
                    
                    Este tensor se veria (de manera general) asi:

                    \[
                    W = \begin{bmatrix}
                        w_{11} & w_{12} & \cdots & w_{1c} \\
                        w_{21} & w_{22} & \cdots & w_{2c} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        w_{b1} & w_{b2} & \cdots & w_{bc}
                    \end{bmatrix}
                    \]
                    
                    De este modo, un elemento escalar \(W_{bc}\) representa el peso que modula la influencia de la \(b\)-ésima característica de entrada sobre la \(c\)-ésima predicción de salida.
                </li>
                
                <br>
                
                <li><strong>El Tensor de Sesgo \(B\):</strong> El tensor de sesgo, también conocido como <em>bias</em> o intercepto, actúa como un término de desplazamiento. Permite que el hiperplano del modelo se ajuste verticalmente, sin necesidad de pasar por el origen del espacio de características. Lo definimos con dimensiones \(a \times c\):
                    
                    \[ B \in \mathbb{R}^{a \times c} \]

                    El tensor de sesgo se crea a partir de 2 tensores de orden 2:

                    <br>
                    
                    <ul>
                        <li>
                            Tensor "\(b\)", el cual tiene dimensiones \( 1 \times c\), donde los c-ésimos valores corresponden al sesgo que va a tener cada una de las "neuronas";
                        </li>
                        
                        <br>
                        
                        <li>
                            Tensor "\( 1 \)", el cual tiene dimensiones \( a \times 1 \) y sus valores son simplemente unos.
                        </li>
                    </ul>
                    
                    Con estos 2 "sub-tensores", podemos construir el tensor final \( B \), de manera que cada columna tenga los mismos valores (correspondiente a cada "neurona").

                    Esta operación se realiza (en notación de Einstein) de la siguiente manera:

                    \[
                    B_{ac} = 1_{a \times 1} b_{1 \times c} = \sum 1_{a \times 1} \cdot b_{1 \times c}
                    \]

                    De forma más visual, la generalización sería así:

                    \[
                    B_{ac} = 1_{a \times 1} b_{1 \times c}
                    =
                    \begin{bmatrix}
                        b_{11} & b_{12} & \cdots & b_{1c} \\
                        b_{11} & b_{12} & \cdots & b_{1c} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        b_{11} & b_{12} & \cdots & b_{1c}
                    \end{bmatrix}
                    \]

                    De esta forma, la ecuacion de la regresion lineal seria asi:

                    \[
                    Z_{ac} = X_{ab} \; W_{bc} + 1_{a \times 1} b_{1 \times c} = \left\{ \sum_{b=1}^{b} X_{ab} \times W_{bc} \right\} + 1_{a \times 1} \; b_{1 \times c}
                    \]
                    
                </li>
            </ul>

        <hr>

        <h2><strong>El Forward Pass: De los Datos a la Predicción</strong></h2>
            
            <p>Una vez definidos nuestros tensores, podemos ejecutar el primer paso computacional del ciclo de entrenamiento: el <strong>Forward Pass</strong> o paso hacia adelante. El objetivo de esta fase es tomar nuestros datos de entrada, \(X\), y combinarlos con el estado actual de los parámetros del modelo, \(W\) y \(B\), para generar un conjunto de predicciones. Es en este momento donde la información "fluye" desde la entrada, a través de la estructura matemática del modelo, hasta producir una salida.</p>
            
            <p>La operación que define este proceso es la transformación lineal que postulamos en nuestra hipótesis inicial. Su formalización matemática, extraída directamente de nuestro desarrollo, es la siguiente:</p>
            
            \[
            Z_{ac} = X_{ab} ; W_{bc} + B_{ac}
            \]
            
            <p>Esta ecuación define el tensor de salida de nuestro modelo, \(Z\), el cual, por construcción, tendrá las mismas dimensiones que nuestro tensor objetivo \(Y\), es decir, \(Z \in \mathbb{R}^{a \times c}\). Analicemos cada componente de esta operación fundamental.</p>
            
            <h3><strong>La Suma Ponderada de Características</strong></h3>
            
            <p>El núcleo de la ecuación reside en el término \(X_{ab} ; W_{bc}\). Siguiendo la convención de notación de Einstein, observamos que el índice \(b\) se repite. Esto nos indica que debemos realizar una suma sobre todas las dimensiones de las características. De forma explícita, la operación es:</p>
            
            \[ 
            \sum_{b=1}^{b} X_{ab} ; W_{bc}
            \]
            
            <p>Conceptualmente, esta operación calcula una <strong>suma ponderada</strong>. Para una muestra específica \(a\) y una clase de salida \(c\), el modelo recorre cada una de las \(b\) características de esa muestra. El valor de cada característica, \(X_{ab}\), se multiplica por su peso correspondiente, \(W_{bc}\), que lo conecta con la clase de salida \(c\). El resultado de la suma es la contribución agregada de todas las características a la predicción final para esa muestra y esa clase. Los índices que no se suman, \(a\) y \(c\), se conocen como índices "libres" y determinan la forma del tensor resultante de esta multiplicación.</p>
            
            <h3><strong>La Incorporación del Sesgo</strong></h3>
            
            <p>Una vez calculada esta suma ponderada, el segundo paso es añadir el término de sesgo, \(+ B_{ac}\). Esta es una simple adición elemento a elemento. Como recordaremos de nuestra definición de \(B\), el valor de \(B_{ac}\) es constante para todas las muestras \(a\) dentro de una misma columna (o clase) \(c\). La función de este término es crucial: permite que el hiperplano de nuestro modelo se desplace verticalmente, otorgándole la flexibilidad necesaria para ajustarse a datos que no están centrados en el origen.</p>
            
            <h3><strong>El Resultado: El Tensor de Predicciones Lineales</strong></h3>
            
            <p>El resultado final de esta operación es el tensor \(Z \in \mathbb{R}^{a \times c}\), al que nos referiremos como el <strong>tensor de predicciones lineales</strong> o las <strong>salidas crudas del modelo</strong>. Cada elemento escalar \(Z_{ac}\) representa la predicción directa y sin transformar del modelo para la \(a\)-ésima muestra y la \(c\)-ésima clase.</p>
            
            <p>Hemos completado con éxito el primer paso: hemos transformado nuestra entrada en una salida. Sin embargo, esta predicción se ha generado utilizando parámetros \(W\) y \(B\) que, al inicio, son probablemente aleatorios y, por tanto, incorrectos. El siguiente paso lógico e indispensable es cuantificar exactamente <em>cuán</em> incorrectas son estas predicciones. Para ello, debemos introducir una <strong>función de pérdida</strong>.</p>
            
            <hr>

        <h2><strong>Cálculo de la Pérdida: Cuantificando el Error del Modelo</strong></h2>
            
            <p>El Forward Pass nos ha proporcionado un tensor de predicciones lineales, \(Z\). Sin embargo, por sí solo, este tensor no nos dice nada sobre el rendimiento de nuestro modelo. Para avanzar en el ciclo de entrenamiento, necesitamos un método riguroso para cuantificar la discrepancia total entre nuestras predicciones \(Z\) y los valores verdaderos \(Y\). El objetivo es destilar toda la información de error, que existe para cada punto de datos y cada clase de salida, en un <strong>único valor escalar</strong>. Este escalar, al que llamamos <strong>Pérdida</strong> (<em>Loss</em>), servirá como una medida global y objetiva del rendimiento del modelo en su estado actual.</p>
            
            <p>Para esta tarea, nuestro desarrollo matemático emplea una de las funciones de pérdida más fundamentales y extendidas en problemas de regresión: el <strong>Error Cuadrático Medio</strong> (<em>Mean Squared Error</em> o MSE). Se define de la siguiente manera:</p>
            
            \[ 
            \text{Loss} := \text{MSE} = \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} (Z_{ac} - Y_{ac})^2
            \]
            
            <p>Para comprender verdaderamente lo que esta ecuación representa, deconstruyámosla desde su núcleo hacia el exterior.</p>
            
            <ol>
                <li><strong>El Error Individual: \((Z_{ac} - Y_{ac})\)</strong><br>Todo comienza aquí, con la operación más simple: la diferencia entre el valor predicho \(Z_{ac}\) y el valor real \(Y_{ac}\) para una única muestra \(a\) y una única clase de salida \(c\). Este resultado, conocido como residuo, nos dice la magnitud y dirección del error para un único punto de predicción.</li>
                
                <br>
                
                <li><strong>El Error al Cuadrado: \((\dots)^2\)</strong><br>A continuación, elevamos esta diferencia al cuadrado. Este paso es crucial por dos razones. Primero, <strong>garantiza la positividad</strong>: al elevar al cuadrado, todos los errores (tanto si la predicción fue demasiado alta como demasiado baja) se convierten en valores positivos. Esto evita que errores de signo opuesto se anulen entre sí al sumarlos. Segundo, <strong>penaliza desproporcionadamente los errores grandes</strong>: un error de magnitud 2 contribuye con 4 a la pérdida total, mientras que un error de 10 contribuye con 100. Este comportamiento empuja al algoritmo de optimización a priorizar la corrección de las desviaciones más graves.</li>
                
                <br>
                
                <li><strong>La Suma Total: \(\sum_{a=1}^{a} \sum_{c=1}^{c}\)</strong><br>La doble sumatoria agrega todos estos errores cuadráticos individuales. <br><br> Mientras que la suma sobre las muestras \(a\) es intuitiva —simplemente estamos acumulando el error de cada una de las observaciones en nuestro conjunto de datos—, la suma sobre las clases \(c\) merece una atención especial.<br><br>Nuestro formalismo es general, diseñado para manejar modelos que pueden predecir múltiples valores simultáneamente (lo que se conoce como regresión multivariable). Imaginemos un caso en el que, para una entrada, predecimos tanto una altura como un ancho. Para esa única muestra, tendríamos un error en la predicción de la altura y otro en la del ancho. La función de pérdida debe consolidar estos errores en un único número que represente el rendimiento para esa muestra. La suma interna sobre \(c\) logra precisamente esto: <strong>agrega los errores cuadráticos de todas las dimensiones de salida para una muestra dada</strong>, dándonos el error total para esa única observación. Posteriormente, la suma externa sobre \(a\) acumula estos errores por muestra para obtener el error cuadrático total de todo el conjunto de datos.</li>
                
                <br>
                
                <li><strong>El Promedio: \(\frac{1}{n}\)</strong><br>Finalmente, dividimos la suma total por \(n\). Este término es una constante de normalización, donde \(n\) suele ser el número de muestras (\(a\)) o el número total de elementos (\(a \times c\)). Su propósito es hacer que el valor de la pérdida sea independiente del tamaño del lote de datos que estemos utilizando. Esto nos permite comparar de manera justa el rendimiento del modelo entre diferentes iteraciones o con diferentes conjuntos de datos.</li>
            </ol>
            
            <h3><strong>El Objetivo Final: Minimizar la Pérdida</strong></h3>
            
            <p>Es vital entender que el valor escalar del MSE no es simplemente una métrica de reporte. Es el <strong>objetivo central de nuestra optimización</strong>. Todo el proceso de entrenamiento se puede resumir en una sola meta: encontrar la combinación de parámetros en los tensores \(W\) y \(B\) que haga que el valor de esta función de pérdida sea lo más pequeño posible.</p>
            
            <p>Esto nos lleva a la pregunta que impulsa el resto de nuestro análisis: si tenemos un valor de pérdida, ¿cómo sabemos en qué dirección debemos ajustar los miles o millones de parámetros en \(W\) y \(B\) para reducirla? La respuesta no está en la intuición, sino en el cálculo diferencial. Necesitamos determinar la influencia de cada parámetro individual en el error total. Este es el propósito del <strong>Backward Pass</strong>.</p>
        
        <hr>

        <h2><strong>El Backward Pass: Rastreando la Influencia de Cada Parámetro</strong></h2>
            
            <p>Hemos cuantificado el error de nuestro modelo en un único escalar: la pérdida (MSE). Ahora nos enfrentamos a la pregunta central del aprendizaje: ¿cómo ajustamos los millones de parámetros en \(W\) y \(B\) para minimizar esta pérdida? La respuesta reside en el <strong>Backward Pass</strong>, un proceso elegante que utiliza el cálculo diferencial para determinar la contribución de cada parámetro individual al error total.</p>
            
            <p>El objetivo es calcular las derivadas parciales de la pérdida con respecto a cada elemento de nuestros tensores de parámetros. Estas derivadas, conocidas como gradientes, nos indicarán la dirección de máximo ascenso de la función de pérdida. Para minimizarla, simplemente daremos un pequeño paso en la dirección opuesta.</p>
            
            <p>Para mantener la consistencia dimensional, adoptaremos la <strong>convención de diseño del numerador</strong> (<em>numerator layout</em>). Esto significa que el resultado de una derivada tendrá dimensiones del numerador x denominador. Por ejemplo, el tensor de gradientes \(\frac{\partial Z}{\partial W}\) será un tensor de dimensiones \(a \times c \times b \times c \; \) ( \( a \times c \; \) son las dimensiones del tensor del numerador, y \( \; b \times c \; \) son las dimensiones del tensor del denominador).</p>
            
            <h3><strong>La Estrategia y una Aclaración Notacional Crucial</strong></h3>
            
            <p>Observando el diagrama de "Paths of Influence", vemos que los parámetros \(W\) y \(B\) no afectan la pérdida directamente. Su influencia es indirecta, mediada por el tensor de predicciones \(Z\). Esta estructura de dependencias nos obliga a usar la <strong>regla de la cadena</strong> del cálculo multivariable.</p>
            
            <p>Antes de aplicar la regla, debemos hacer una aclaración notacional fundamental. Al calcular la derivada de una función que contiene sumas (como el MSE o \(Z_{ac}\)) con respecto a un elemento específico de un tensor (por ejemplo, un peso particular), debemos distinguir entre los índices de la suma y los índices del elemento por el cual derivamos.</p>
            
            <ul>
                <li>Los índices dentro de una suma (\(a, b, c\)) son variables "mudas" o locales a esa suma.</li>
                
                <li>Los índices del elemento por el cual derivamos son "fijos" y definen una coordenada específica en el tensor de gradientes.</li>
            </ul>
            
            <p>Para evitar ambigüedad, usaremos un apóstrofe (') para los índices fijos. Así, calcularemos \(\frac{\partial \text{MSE}}{\partial W_{b'c'}}\) para encontrar el elemento en la fila \(b'\) y la columna \(c'\) del gradiente de los pesos.</p>

            <p>De todas formas, en ultima instancia, los indices con apoostrofe (') tienen los mismos valores que sus "gemelos".</p>

            <h3><strong>Paso 1: El Gradiente Intermedio \(\frac{\partial \text{MSE}}{\partial Z_{ac}}\)</strong></h3>
            
                <p>Viendo el camino de influencias, el primer paso, común a ambos gradientes de parámetros, es calcular cómo cambia la pérdida con respecto a un cambio en una predicción \(Z_{ac}\). Para construir el tensor de gradientes \(\frac{\partial \text{MSE}}{\partial Z}\), calculamos la derivada para un elemento genérico \(\frac{\partial \text{MSE}}{\partial Z_{a'c'}}\).</p>
                
                <p>Partimos de la definición del MSE:</p>
                
                \[ 
                \text{MSE} = \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} (Z_{ac} - Y_{ac})^2 
                \]
                
                <p>Aplicamos la derivada \( \frac{\partial}{\partial Z_{a'c'}} \) a toda la expresión:</p> 
    
                \[
                \frac{\partial \text{MSE}}{\partial Z_{a'c'}} = \frac{\partial}{\partial Z_{a'c'}} \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} (Z_{ac} - Y_{ac})^2
                \]
                
                <p>El escalar \( \frac{1}{n} \) esta multiplicando, por lo que lo podemos sacar fuera de la derivada:</p>
                
                \[
                \frac{\partial \text{MSE}}{\partial Z_{a'c'}} = \frac{1}{n} \frac{\partial}{\partial Z_{a'c'}} \sum_{a=1}^{a} \sum_{c=1}^{c} (Z_{ac} - Y_{ac})^2
                \]
                
                <p>La derivada puede pasar a través de la suma:</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial Z_{a'c'}} = \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} \frac{\partial}{\partial Z_{a'c'}} (Z_{ac} - Y_{ac})^2
                \]
                
                <p>Usando la regla de la cadena, la derivada del término al cuadrado es:</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial Z_{a'c'}} = \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} 2(Z_{ac} - Y_{ac}) \cdot \frac{\partial (Z_{ac} - Y_{ac})}{\partial Z_{a'c'}} 
                \]
                
                <p>En la derivada interna, el elemento \( Y_{ac} \) es una variable constante con respecto a \( Z_{a'c'} \), por lo que su valor es simplemente 0. Ahora, la derivada de lo que queda del término interno, \( \frac{\partial Z_{ac}}{\partial Z_{a'c'}} \), es 1 si y solo si los índices coinciden ( \( a=a' \) y \( c=c' \) ), y 0 en caso contrario. Esta es precisamente la definición del producto de dos <strong>Deltas de Kronecker</strong>: \( \delta_{aa'} \delta_{cc'} \).</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial Z_{a'c'}} = \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} 2(Z_{ac} - Y_{ac}) \cdot \delta_{aa'} \delta_{cc'} 
                \]
                
                <p>El Delta de Kronecker tiene una propiedad fundamental: cuando multiplica a una expresión dentro de una suma, <strong>colapsa la suma</strong>. La presencia de \( \delta_{aa'} \) hace que todos los términos de la suma sobre \( a \) se anulen, excepto el único término donde \( a=a' \). Lo mismo ocurre con \( \delta_{cc'} \) y la suma sobre \( c \). Como resultado, las sumas desaparecen y los índices mudos \( a \) y \( c \) son <strong>sustituidos</strong> por los índices fijos \( a' \) y \( c' \):</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial Z_{a'c'}} = \frac{1}{n} \cdot 2(Z_{a'c'} - Y_{a'c'}) 
                \]
                
                <p>Al generalizar esto de un elemento específico a la forma tensorial completa (reemplazando \(a', c'\) por \(a, c\)), obtenemos nuestro gradiente intermedio:</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial Z} = \frac{2(Z - Y)}{n} 
                \]
            

            <h3><strong>Paso 2: El Gradiente de los Pesos \(\frac{\partial \text{MSE}}{\partial W}\)</strong></h3>
            
                <p>Ahora aplicamos la regla de la cadena para encontrar el gradiente con respecto a un peso genérico \(W_{b'c'}\). La influencia de \(W_{b'c'}\) se propaga a través de todos los elementos de \(Z\), por lo que debemos sumar todas estas contribuciones:</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial W_{b'c'}} = \sum_{a,c} \frac{\partial \text{MSE}}{\partial Z_{ac}} \frac{\partial Z_{ac}}{\partial W_{b'c'}} 
                \]
                
                <p>Ya conocemos el primer término. Nos enfocamos en el segundo: \(\frac{\partial Z_{ac}}{\partial W_{b'c'}}\). Partimos de la definición de \(Z_{ac}\):</p>
                
                \[ 
                \frac{\partial Z_{ac}}{\partial W_{b'c'}} = \frac{\partial}{\partial W_{b'c'}} \left( \sum_{b} X_{ab}W_{bc} + B_{ac} \right) 
                \]
                
                <p>El término \(B_{ac}\) es constante con respecto a \(W\), por lo que su derivada es 0. Dentro de la suma, \(X_{ab}\) es un multiplicador constante. La derivada de \(W_{bc}\) con respecto a \(W_{b'c'}\) es, nuevamente, un Delta de Kronecker: \(\delta_{bb'} \delta_{cc'}\).</p>
                
                \[ 
                \frac{\partial Z_{ac}}{\partial W_{b'c'}} = \sum_{b} X_{ab} (\delta_{bb'} \delta_{cc'}) 
                \]
                
                <p>El delta \(\delta_{bb'}\) colapsa la suma sobre \(b\), sustituyendo el índice \(b\) por \(b'\). El delta \(\delta_{cc'}\) simplemente permanece.</p>
                
                \[ 
                \frac{\partial Z_{ac}}{\partial W_{b'c'}} = X_{ab'} \delta_{cc'} 
                \]

            
            <h3><strong>Paso 3: El Gradiente del Sesgo \(\frac{\partial \text{MSE}}{\partial B}\)</strong></h3>
            
                <p>El proceso para el sesgo es análogo. Aplicamos la regla de la cadena:</p>
                
                \[ 
                \frac{\partial \text{MSE}}{\partial B_{a'c'}} = \sum_{a,c} \frac{\partial \text{MSE}}{\partial Z_{ac}} \frac{\partial Z_{ac}}{\partial B_{a'c'}} 
                \]
                
                <p>Calculamos la derivada de \(Z_{ac}\) con respecto a un elemento genérico del sesgo, \(B_{a'c'}\):</p>
                
                \[ 
                \frac{\partial Z_{ac}}{\partial B_{a'c'}} = \frac{\partial}{\partial B_{a'c'}} \left( \sum_{b} X_{ab}W_{bc} + B_{ac} \right) 
                \]
                
                <p>Aquí, el término de la suma es constante y su derivada es 0. La derivada de \(B_{ac}\) con respecto a \(B_{a'c'}\) es simplemente \(\delta_{aa'} \delta_{cc'}\).</p>
                
                \[ 
                \frac{\partial Z_{ac}}{\partial B_{a'c'}} = \delta_{aa'} \delta_{cc'} 
                \]
                
                <p>Hemos derivado con éxito las expresiones para los componentes de nuestros gradientes. Sin embargo, si observamos las fórmulas completas de la regla de la cadena, vemos que implican sumas sobre múltiples índices y la manipulación de tensores de 4º orden (por ejemplo, \(\frac{\partial Z_{ac}}{\partial W_{b'c'}}\) es un tensor con cuatro índices). Implementar esto directamente sería extremadamente ineficiente.</p>
                
                <p>Afortunadamente, la estructura de estas ecuaciones y las propiedades del Delta de Kronecker nos permiten simplificar drásticamente estas operaciones, reduciéndolas a multiplicaciones de matrices eficientes, como veremos a continuación.</p>

        <hr>

        <h2><strong>Optimización: Cerrando el Ciclo con Descenso de Gradiente</strong></h2>
        
            <p>Hemos llegado al último eslabón de nuestra cadena lógica. A través del Forward Pass, generamos predicciones; con la función de pérdida, cuantificamos su error; y mediante el Backward Pass, calculamos los gradientes, \(\frac{\partial \text{MSE}}{\partial W}\) y \(\frac{\partial \text{MSE}}{\partial B}\). Ahora nos encontramos en posesión de la información más valiosa para el aprendizaje: sabemos exactamente cómo un pequeño cambio en cada peso y sesgo afectará al error total. La pregunta final es: ¿qué hacemos con esta información?</p>
            
            <p>La respuesta se encuentra en el proceso de <strong>optimización</strong>. Los gradientes que hemos calculado tienen una interpretación geométrica fundamental: son tensores que, para cada parámetro, apuntan en la dirección de <strong>máximo ascenso</strong> en la "superficie de la pérdida". En otras palabras, nos indican la forma más rápida de <em>aumentar</em> el error. Nuestro objetivo, por supuesto, es el opuesto.</p>

            <h3><strong>La Intuición del Descenso</strong></h3>
            
                <p>Si el gradiente representa la "cuesta arriba" más pronunciada, entonces su negativo, <strong>el negativo del gradiente</strong>, debe representar la "cuesta abajo" más pronunciada. Esta es la idea central del algoritmo de optimización más fundamental: el <strong>Descenso de Gradiente</strong> (<em>Gradient Descent</em>). Para reducir nuestra pérdida, daremos un pequeño paso en la dirección opuesta a la del gradiente.</p>
                
                <p>Sin embargo, no podemos simplemente restar el gradiente completo de nuestros parámetros. Hacerlo sería dar un paso de un tamaño arbitrario, lo que podría llevarnos a "saltar" por encima del punto mínimo de la superficie de pérdida y terminar en un lugar con un error aún mayor. Necesitamos controlar el tamaño de nuestro paso.</p>

            <h3><strong>Formalización de la Regla de Actualización</strong></h3>
            
                <p>Para modular la magnitud de nuestra actualización, introducimos un hiperparámetro clave: la <strong>tasa de aprendizaje</strong> (<em>learning rate</em>), denotada por el escalar \(\alpha\). Este es un número pequeño y positivo (por ejemplo, 0.01) que actúa como un factor de escala para el gradiente. Controla cuán agresivamente ajustamos nuestros parámetros en cada iteración del entrenamiento.</p>
                
                <p>Con este último componente, podemos formular las reglas de actualización que definen el algoritmo de Descenso de Gradiente:</p>
            
                \[ 
                W_{\text{nuevo}} = W_{\text{viejo}} - \alpha \frac{\partial \text{MSE}}{\partial W} 
                \]
                
                \[ 
                B_{\text{nuevo}} = B_{\text{viejo}} - \alpha \frac{\partial \text{MSE}}{\partial B} 
                \]
                
                <p>Cada parte de esta ecuación tiene un propósito claro: actualizamos el valor de un parámetro (\(W_{\text{viejo}}\)) moviéndolo en la dirección del gradiente negativo (\(-\frac{\partial \text{MSE}}{\partial W}\)), con un tamaño de paso controlado por la tasa de aprendizaje (\(\alpha\)).</p>
            
            <h3><strong>El Ciclo de Entrenamiento Completo</strong></h3>
            
                <p>Esta actualización no es un evento aislado, sino el paso final de un proceso iterativo que constituye el corazón del aprendizaje automático. El ciclo de entrenamiento completo, ahora con sus cuatro etapas explícitas, es el siguiente:</p>
                
                <ol>
                    <li><strong>Forward Pass:</strong> Con los parámetros \(W\) y \(B\) actuales, calcular las predicciones \(Z = XW + B\).</li>
                    
                    <li><strong>Loss Computation:</strong> Calcular el error escalar \(\text{MSE}\) comparando \(Z\) con los valores reales \(Y\).</li>
                    
                    <li><strong>Backward Pass:</strong> Calcular los tensores de gradientes, \(\frac{\partial \text{MSE}}{\partial W}\) y \(\frac{\partial \text{MSE}}{\partial B}\), utilizando las fórmulas simplificadas que derivamos.</li>
                    
                    <li><strong>Optimización:</strong> Actualizar los parámetros \(W\) y \(B\) utilizando las reglas de actualización del Descenso de Gradiente.</li>
                </ol>
                
                <p>Este ciclo se repite una y otra vez. Con cada iteración, los parámetros del modelo se refinan sutilmente, "descendiendo" gradualmente por la superficie de la pérdida. Si la tasa de aprendizaje está bien elegida, este proceso iterativo convergerá hacia un conjunto de parámetros que minimizan el error, resultando en un modelo que ha "aprendido" la relación lineal subyacente en los datos.</p>
                
                <p>Hemos completado nuestro viaje, partiendo de la simple observación de una tendencia en los datos y llegando a la construcción de un algoritmo de optimización funcional, todo ello derivado desde los primeros principios matemáticos. Hemos diseccionado el funcionamiento interno de la Regresión Lineal, no como una caja negra, sino como un objeto matemático elegante y comprensible.</p>

        <hr>
            
        <h2><strong>De la Teoría a la Práctica: Simplificación del Backward Pass</strong></h2>

            <p>En la sección anterior, derivamos con éxito las expresiones para los gradientes de la pérdida con respecto a cada uno de nuestros parámetros. Sin embargo, nos encontramos con un dilema computacional. La aplicación directa de la regla de la cadena, tal como la formulamos, implica la creación conceptual de tensores de 4º orden (por ejemplo, \(\frac{\partial Z_{ac}}{\partial W_{b'c'}}\)). Estos objetos matemáticos, aunque teóricamente correctos, serían desastrosos en la práctica. Serían "súper dispersos", es decir, estarían llenos casi en su totalidad de ceros, ocupando una cantidad masiva de memoria para almacenar muy poca información útil.</p>
            
            <p>Afortunadamente, no necesitamos construir estos tensores. La belleza de la notación de Einstein y las propiedades del Delta de Kronecker nos permiten simplificar algebraicamente estas complejas expresiones, reduciéndolas a operaciones de tensores de rango 2 (matrices) que son la base del cálculo numérico eficiente.</p>
                
                <h3><strong>Simplificación del Gradiente de los Pesos (\(\frac{\partial \text{MSE}}{\partial W}\))</strong></h3>
            
                    <p>Comencemos con la expresión completa de la regla de la cadena para un único elemento del gradiente de los pesos, \(\frac{\partial \text{MSE}}{\partial W_{b'c'}}\):</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial W_{b'c'}} = \sum_{a=1}^{a} \sum_{c=1}^{c} \frac{\partial \text{MSE}}{\partial Z_{ac}} \frac{\partial Z_{ac}}{\partial W_{b'c'}}
                    \]
                    
                    <p>Ahora, sustituimos la expresión que ya encontramos para \(\frac{\partial Z_{ac}}{\partial W_{b'c'}}\), que es \(X_{ab'} \delta_{cc'}\):</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial W_{b'c'}} = \sum_{a=1}^{a} \sum_{c=1}^{c} \frac{\partial \text{MSE}}{\partial Z_{ac}} (X_{ab'} \delta_{cc'}) 
                    \]
                    
                    <p>Aquí es donde ocurre la primera simplificación. Como se anota en nuestro desarrollo manuscrito, el Delta de Kronecker \(\delta_{cc'}\) actúa como un filtro sobre la suma interna en \(c\). Anula todos los términos de la suma excepto el único en el que \(c = c'\). Esto nos permite <strong>colapsar la suma sobre \(c\)</strong> y, en el proceso, <strong>sustituir el índice \(c\) por \(c'\)</strong> en el resto de la expresión:</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial W_{b'c'}} = \sum_{a=1}^{a} \frac{\partial \text{MSE}}{\partial Z_{ac'}} X_{ab'} 
                    \]
            
                    <p>Analicemos esta expresión resultante. Para calcular un único elemento del gradiente, indexado por \((b', c')\), estamos realizando una suma sobre el índice de las muestras, \(a\). Los dos términos dentro de la suma, \(\frac{\partial \text{MSE}}{\partial Z_{ac'}}\) y \(X_{ab'}\), son elementos de dos tensores de rango 2 (matrices). Una suma sobre un índice repetido entre dos tensores de esta manera es, por definición, la operación que construye un elemento de una multiplicación de matrices.</p>
                    
                    <p>Si esta suma calcula un solo elemento, entonces la operación para calcular el tensor de gradiente completo, \(\frac{\partial \text{MSE}}{\partial W}\), debe ser una multiplicación de matrices. Sin embargo, debemos ser cuidadosos con las dimensiones. Tenemos el tensor \(X\) con dimensiones \((a \times b)\) y el tensor \(\frac{\partial \text{MSE}}{\partial Z}\) con dimensiones \((a \times c)\). Para producir un tensor de gradiente con las dimensiones correctas de \(W\), que son \((b \times c)\), la operación matricial correcta es multiplicar la transpuesta de \(X\) por el gradiente intermedio:</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial W} = (X)^T \left( \frac{\partial \text{MSE}}{\partial Z} \right) 
                    \]
                    
                    <p>Verificamos las dimensiones: \((b \times a) \cdot (a \times c) \rightarrow (b \times c)\). La operación es dimensionalmente consistente y computacionalmente eficiente.</p>
                
                <h3><strong>Simplificación del Gradiente del Sesgo (\(\frac{\partial \text{MSE}}{\partial B}\))</strong></h3>
            
                    <p>Sigamos un proceso similar para el gradiente del sesgo. Partimos de la expresión de la regla de la cadena para un elemento \(\frac{\partial \text{MSE}}{\partial B_{a'c'}}\):</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial B_{a'c'}} =  
                    \]
                    
                    <p>Sustituimos la expresión que encontramos para \(\frac{\partial Z_{ac}}{\partial B_{a'c'}}\), que es el producto de dos Deltas de Kronecker, \(\delta_{aa'} \delta_{cc'}\):</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial B_{a'c'}} = \sum_{a=1}^{a} \sum_{c=1}^{c} \frac{\partial \text{MSE}}{\partial Z_{ac}} (\delta_{aa'} \delta_{cc'}) 
                    \]
                    
                    <p>Aquí, la simplificación es aún más dramática. El delta \(\delta_{cc'}\) colapsa la suma sobre \(c\), reemplazando \(c\) por \(c'\). Inmediatamente después, el delta \(\delta_{aa'}\) colapsa la suma restante sobre \(a\), reemplazando \(a\) por \(a'\). Ambas sumas desaparecen, dejándonos con un resultado sorprendentemente simple:</p>
                    
                    \[ 
                    \frac{\partial \text{MSE}}{\partial B_{a'c'}} = \frac{\partial \text{MSE}}{\partial Z_{a'c'}} 
                    \]
                    
                    <p>En su forma tensorial, esto implica que el gradiente de la pérdida con respecto al sesgo es simplemente el gradiente intermedio que ya habíamos calculado. En implementaciones prácticas, a menudo se realiza un paso adicional de sumar o promediar este gradiente a lo largo del eje de las muestras (\(a\)) para obtener un único vector de gradiente de tamaño \(c\), que corresponde a la naturaleza conceptual de nuestro sesgo.</p>     
