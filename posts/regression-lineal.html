<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fundamentos de la Regresion Lineal</title>
    
    <link rel="stylesheet" href="../style.css"> 
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!-- Mantenemos la combinación original que te gustó -->
    <link href="https://fonts.googleapis.com/css2?family=Lora:ital,wght@0,400;0,700;1,400&family=Source+Code+Pro:wght@400;700&display=swap" rel="stylesheet">
    
    <!-- Hoja de estilos de Prism.js (tema oscuro "Tomorrow Night") -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

    <main class="post-full">
        <header class="post-header">
            <h1>Fundamentos de la Regresion Lineal</h1>
            <p class="post-meta">15 of October, 2025</p>
        </header>

        <article class="post-content">

          <h2><strong>El Fundamento de la Predicción: Una Introducción a la Regresión Lineal desde los Primeros Principios</strong></h2>

          <p>En el estudio de cualquier fenómeno, nuestro punto de partida es casi siempre el mismo: la observación de los datos. Imaginemos que hemos recolectado un conjunto de mediciones, donde para cada observación disponemos de un conjunto de variables de entrada y un valor de salida correspondiente. Al visualizar estos datos, por ejemplo, en un simple gráfico de dispersión, podríamos notar una tendencia reveladora: los puntos parecen agruparse en torno a una línea recta.</p>

          <p>Esta observación visual, aunque simple, es profundamente significativa. Sugiere que podría existir una relación funcional subyacente que conecta nuestras entradas con nuestras salidas. Ante esta evidencia, nos planteamos una pregunta fundamental: ¿cuál es la estructura matemática más simple y fundamental que podría describir esta tendencia? La respuesta, por supuesto, es la ecuación de una recta.</p>

          <h3><strong>La Hipótesis de Linealidad</strong></h3>

            <p>Esto nos lleva a formular nuestra hipótesis central: <strong>asumimos que la relación entre las variables de entrada y las de salida es de naturaleza lineal</strong>. Este es el nacimiento conceptual del modelo de <strong>Regresión Lineal</strong>.</p> 
            
            <p>No pretendemos que los datos se ajusten perfectamente a una línea; el mundo real es inherentemente ruidoso y complejo. En cambio, nuestro objetivo es encontrar la línea "óptima" que mejor represente la tendencia general contenida en los datos, minimizando la distancia promedio entre la línea y cada punto de datos.</p>
  
            <p>En un caso simple con una sola variable de entrada, esta idea se materializa en la conocida ecuación \(y = mx + b\). Sin embargo, en el dominio de la inteligencia artificial, rara vez trabajamos con una única variable de entrada. Generalmente, cada muestra de nuestros datos está definida por un conjunto de \(b\) características o <em>features</em>. Por lo tanto, debemos generalizar nuestra noción de "línea" desde un plano bidimensional a un espacio de alta dimensionalidad. En este nuevo contexto, nuestra "línea" se convierte en un <strong>hiperplano</strong>.</p>
  
            <p>La formalización matemática de esta transformación lineal, que constituye el corazón de nuestro modelo, se expresa de la siguiente manera:</p>
            
            \[ Z_{ac} = X_{ab}W_{bc} + B_{ac} \]
            
            <p>Aquí, \(X\) representa nuestros datos de entrada, mientras que \(W\) (los pesos) y \(B\) (el sesgo) son los parámetros del modelo que debemos "aprender". El tensor \(Z\) contendrá las predicciones generadas por el modelo.</p>

          <h3><strong>El Objetivo: Aprender a Predecir</strong></h3>
          
            <p>El propósito del "aprendizaje" en este modelo es, precisamente, encontrar los valores numéricos para los tensores \(W\) y \(B\) que hagan que nuestras predicciones, \(Z\), sean lo más cercanas posible a los valores reales observados, que llamaremos \(Y\). Para lograr esto, nos embarcamos en un proceso iterativo conocido como el <strong>Ciclo de Entrenamiento</strong> (<em>Training Cycle</em>). Este ciclo, que exploraremos en detalle a lo largo de este artículo, se compone de cuatro etapas conceptuales:</p>
            
            <ol>
                
                <li><strong>Forward Pass (Paso hacia adelante):</strong> Utilizando una estimación inicial de \(W\) y \(B\), aplicamos la ecuación del modelo a nuestros datos de entrada \(X\) para generar un conjunto de predicciones \(Z\).</li>
                <br>
                <li><strong>Loss Computation (Cálculo de la Périda):</strong> Medimos qué tan erróneas son nuestras predicciones comparando \(Z\) con los valores verdaderos \(Y\). Esta medida de error se cuantifica en un único valor escalar llamado "périda" (<em>loss</em>).</li>
                <br>
                <li><strong>Backward Pass (Paso hacia atrás):</strong> Aquí es donde interviene el cálculo. Determinamos cómo un pequeño cambio en cada uno de los parámetros de \(W\) y \(B\) afectaría la pérdida total. Este proceso nos da los gradientes, que nos indican la dirección en la que debemos ajustar nuestros parámetros para reducir el error.</li>
                <br>
                <li><strong>Optimization (Optimización):</strong> Finalmente, actualizamos los valores de \(W\) y \(B\) moviéndolos ligeramente en la dirección opuesta a sus gradientes, acercándonos un paso más a la configuración óptima que minimiza el error.</li>
            
            </ol>
            
            <p>Este ciclo se repite una y otra vez, refinando progresivamente los parámetros del modelo hasta que nuestras predicciones sean lo más precisas posible.</p>
            
            <p>Antes de sumergirnos en la mecánica de este ciclo, es imperativo establecer un lenguaje común. Nuestro primer paso será definir formalmente las estructuras de datos, o tensores, con las que operaremos, estableciendo las convenciones de notación que nos guiarán a través de este desarrollo matemático.</p>

            <hr>

            <h2><strong>Formalización Matemática: Definiendo los Tensores del Modelo</strong></h2>
            
            <p>Para construir nuestro modelo de Regresión Lineal sobre una base rigurosa, debemos primero definir con precisión los objetos matemáticos que lo componen. En este contexto, trataremos todas nuestras estructuras de datos —entradas, salidas y parámetros— como <strong>tensores</strong>. Un tensor es una generalización de vectores y matrices a un número arbitrario de dimensiones, y nos proporciona un marco robusto para describir las operaciones de nuestro modelo.</p>
            
            <p>Para manipular estos tensores, emplearemos exclusivamente la <strong>notación de Einstein</strong>. Esta convención es a la vez elegante y poderosa: cualquier índice que aparezca repetido en un mismo término implica una suma sobre todos los valores posibles de dicho índice. Por ejemplo, un término como \(X_{ab}W_{bc}\) es una forma compacta de escribir \(\sum_{b} X_{ab}W_{bc}\). Esta notación nos permitirá expresar operaciones complejas, como la multiplicación de matrices, sin la ambigüedad de la notación matricial tradicional, enfocándonos en la interacción entre las dimensiones.</p>
            
            <h3><strong>Los Datos: Entrada y Salida</strong></h3>
            
            <p>Nuestros datos consisten en dos componentes principales: las observaciones de entrada y los valores objetivo correspondientes.</p>
            
            <ul>
                <li><strong>El Tensor de Entrada \(X\):</strong> Este tensor contiene el conjunto completo de nuestras observaciones. Lo definimos como un tensor de rango 2 (una matriz) de dimensiones \(a \times b\):
                    
                    \[ X \in \mathbb{R}^{a \times b} \]
                    
                    Los índices tienen un significado preciso:
                    
                    <br>
                    
                    <ul>
                        <li>El índice \(a\) recorre las <strong>muestras</strong> (<em>samples</em>) de nuestro conjunto de datos, desde \(1\) hasta el número total de observaciones.</li>

                        <br>
                        
                        <li>El índice \(b\) recorre las <strong>características</strong> (<em>features</em>) que describen cada muestra.</li>
                    </ul>

                    <br>
                    
                    Este tensor se veria (de manera general) asi:

                    \[
                    X = \begin{bmatrix}
                        x_{11} & x_{12} & \cdots & x_{1b} \\
                        x_{21} & x_{22} & \cdots & x_{2b} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        x_{a1} & x_{a2} & \cdots & x_{ab}
                    \end{bmatrix}
                    \]
                    
                    Así, un elemento escalar \(X_{ab}\) representa el valor de la \(b\)-ésima característica para la \(a\)-ésima muestra de nuestros datos.
                </li>
                
                <br>
                
                <li><strong>El Tensor Objetivo \(Y\):</strong> Este tensor alberga los valores verdaderos que nuestro modelo aspira a predecir. Al igual que \(X\), es un tensor de rango 2, pero con dimensiones \(a \times c\):
                    
                    \[ Y \in \mathbb{R}^{a \times c} \]
                    
                    El significado de sus índices es el siguiente:

                    <br><br>
                    
                    <ul>
                        <li>El índice \(a\) corresponde directamente al índice de muestras de \(X\), asegurando una alineación perfecta entre cada entrada y su salida esperada.</li>
                        
                        <br>

                        <li>El índice \(c\) recorre las <strong>clases</strong> o variables de salida. En el caso más simple de regresión, \(c\) podría ser 1, pero esta notación nos permite manejar modelos que predicen múltiples valores simultáneamente.</li>
                    </ul>

                    <br>
                    
                    Este tensor se veria (de manera general) asi:

                    \[
                    Y = \begin{bmatrix}
                        y_{11} & y_{12} & \cdots & y_{1c} \\
                        y_{21} & y_{22} & \cdots & y_{2c} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        y_{a1} & y_{a2} & \cdots & y_{ac}
                    \end{bmatrix}
                    \]
                    
                    Un elemento \(Y_{ac}\) es, por tanto, el valor real de la \(c\)-ésima variable de salida para la \(a\)-ésima muestra.
                </li>
            </ul>
            
            <h3><strong>Los Parámetros del Modelo: Pesos y Sesgo</strong></h3>
            
            <p>Los parámetros del modelo son los valores numéricos que no se derivan de los datos, sino que son "aprendidos" durante el proceso de entrenamiento. Son las "perillas" que ajustaremos para minimizar el error de predicción.</p>
            
            <ul>
                <li><strong>El Tensor de Pesos \(W\):</strong> El tensor de pesos \(W\) captura la fuerza y el signo de la relación entre cada característica de entrada y cada clase de salida. Se define como un tensor de rango 2 de dimensiones \(b \times c\):
                    
                    \[ W \in \mathbb{R}^{b \times c} \]
                    
                    La lógica de sus índices es crucial para la conexión entre entrada y salida:
                    
                    <br>
                    
                    <ul>
                        <li>El índice \(b\) se alinea con las \(b\) características del tensor de entrada \(X\).</li>
                        
                        <br>
                        
                        <li>El índice \(c\) se alinea con las \(c\) clases del tensor de salida \(Y\).</li>
                    </ul>

                    <br>
                    
                    Este tensor se veria (de manera general) asi:

                    \[
                    W = \begin{bmatrix}
                        w_{11} & w_{12} & \cdots & w_{1c} \\
                        w_{21} & w_{22} & \cdots & w_{2c} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        w_{b1} & w_{b2} & \cdots & w_{bc}
                    \end{bmatrix}
                    \]
                    
                    De este modo, un elemento escalar \(W_{bc}\) representa el peso que modula la influencia de la \(b\)-ésima característica de entrada sobre la \(c\)-ésima predicción de salida.
                </li>
                
                <br>
                
                <li><strong>El Tensor de Sesgo \(B\):</strong> El tensor de sesgo, también conocido como <em>bias</em> o intercepto, actúa como un término de desplazamiento. Permite que el hiperplano del modelo se ajuste verticalmente, sin necesidad de pasar por el origen del espacio de características. Lo definimos con dimensiones \(a \times c\):
                    
                    \[ B \in \mathbb{R}^{a \times c} \]

                    El tensor de sesgo se crea a partir de 2 tensores de orden 2:

                    <br>
                    
                    <ul>
                        <li>
                            Tensor "\(b\)", el cual tiene dimensiones \( 1 \times c\), donde los c-ésimos valores corresponden al sesgo que va a tener cada una de las "neuronas";
                        </li>
                        
                        <br>
                        
                        <li>
                            Tensor "\( 1 \)", el cual tiene dimensiones \( a \times 1 \) y sus valores son simplemente unos.
                        </li>
                    </ul>
                    
                    Con estos 2 "sub-tensores", podemos construir el tensor final \( B \), de manera que cada columna tenga los mismos valores (correspondiente a cada "neurona").

                    Esta operación se realiza (en notación de Einstein) de la siguiente manera:

                    \[
                    B_{ac} = 1_{a \times 1} b_{1 \times c} = \sum 1_{a \times 1} \cdot b_{1 \times c}
                    \]

                    De forma más visual, la generalización sería así:

                    \[
                    B_{ac} = 1_{a \times 1} b_{1 \times c}
                    =
                    \begin{bmatrix}
                        b_{11} & b_{12} & \cdots & b_{1c} \\
                        b_{11} & b_{12} & \cdots & b_{1c} \\
                        \vdots & \vdots & \ddots & \vdots \\
                        b_{11} & b_{12} & \cdots & b_{1c}
                    \end{bmatrix}
                    \]

                    De esta forma, la ecuacion de la regresion lineal seria asi:

                    \[
                    Z_{ac} = X_{ab} \; W_{bc} + 1_{a \times 1} b_{1 \times c} = \left\{ \sum_{b=1}^{b} X_{ab} \times W_{bc} \right\} + 1_{a \times 1} \; b_{1 \times c}
                    \]
                    
                </li>
            </ul>

        <hr>

        <h2><strong>El Forward Pass: De los Datos a la Predicción</strong></h2>
            
            <p>Una vez definidos nuestros tensores, podemos ejecutar el primer paso computacional del ciclo de entrenamiento: el <strong>Forward Pass</strong> o paso hacia adelante. El objetivo de esta fase es tomar nuestros datos de entrada, \(X\), y combinarlos con el estado actual de los parámetros del modelo, \(W\) y \(B\), para generar un conjunto de predicciones. Es en este momento donde la información "fluye" desde la entrada, a través de la estructura matemática del modelo, hasta producir una salida.</p>
            
            <p>La operación que define este proceso es la transformación lineal que postulamos en nuestra hipótesis inicial. Su formalización matemática, extraída directamente de nuestro desarrollo, es la siguiente:</p>
            
            \[
            Z_{ac} = X_{ab} ; W_{bc} + B_{ac}
            \]
            
            <p>Esta ecuación define el tensor de salida de nuestro modelo, \(Z\), el cual, por construcción, tendrá las mismas dimensiones que nuestro tensor objetivo \(Y\), es decir, \(Z \in \mathbb{R}^{a \times c}\). Analicemos cada componente de esta operación fundamental.</p>
            
            <h3><strong>La Suma Ponderada de Características</strong></h3>
            
            <p>El núcleo de la ecuación reside en el término \(X_{ab} ; W_{bc}\). Siguiendo la convención de notación de Einstein, observamos que el índice \(b\) se repite. Esto nos indica que debemos realizar una suma sobre todas las dimensiones de las características. De forma explícita, la operación es:</p>
            
            \[ 
            \sum_{b=1}^{b} X_{ab} ; W_{bc}
            \]
            
            <p>Conceptualmente, esta operación calcula una <strong>suma ponderada</strong>. Para una muestra específica \(a\) y una clase de salida \(c\), el modelo recorre cada una de las \(b\) características de esa muestra. El valor de cada característica, \(X_{ab}\), se multiplica por su peso correspondiente, \(W_{bc}\), que lo conecta con la clase de salida \(c\). El resultado de la suma es la contribución agregada de todas las características a la predicción final para esa muestra y esa clase. Los índices que no se suman, \(a\) y \(c\), se conocen como índices "libres" y determinan la forma del tensor resultante de esta multiplicación.</p>
            
            <h3><strong>La Incorporación del Sesgo</strong></h3>
            
            <p>Una vez calculada esta suma ponderada, el segundo paso es añadir el término de sesgo, \(+ B_{ac}\). Esta es una simple adición elemento a elemento. Como recordaremos de nuestra definición de \(B\), el valor de \(B_{ac}\) es constante para todas las muestras \(a\) dentro de una misma columna (o clase) \(c\). La función de este término es crucial: permite que el hiperplano de nuestro modelo se desplace verticalmente, otorgándole la flexibilidad necesaria para ajustarse a datos que no están centrados en el origen.</p>
            
            <h3><strong>El Resultado: El Tensor de Predicciones Lineales</strong></h3>
            
            <p>El resultado final de esta operación es el tensor \(Z \in \mathbb{R}^{a \times c}\), al que nos referiremos como el <strong>tensor de predicciones lineales</strong> o las <strong>salidas crudas del modelo</strong>. Cada elemento escalar \(Z_{ac}\) representa la predicción directa y sin transformar del modelo para la \(a\)-ésima muestra y la \(c\)-ésima clase.</p>
            
            <p>Hemos completado con éxito el primer paso: hemos transformado nuestra entrada en una salida. Sin embargo, esta predicción se ha generado utilizando parámetros \(W\) y \(B\) que, al inicio, son probablemente aleatorios y, por tanto, incorrectos. El siguiente paso lógico e indispensable es cuantificar exactamente <em>cuán</em> incorrectas son estas predicciones. Para ello, debemos introducir una <strong>función de pérdida</strong>.</p>
            
            <hr>

        <h2><strong>Cálculo de la Pérdida: Cuantificando el Error del Modelo</strong></h2>
            
            <p>El Forward Pass nos ha proporcionado un tensor de predicciones lineales, \(Z\). Sin embargo, por sí solo, este tensor no nos dice nada sobre el rendimiento de nuestro modelo. Para avanzar en el ciclo de entrenamiento, necesitamos un método riguroso para cuantificar la discrepancia total entre nuestras predicciones \(Z\) y los valores verdaderos \(Y\). El objetivo es destilar toda la información de error, que existe para cada punto de datos y cada clase de salida, en un <strong>único valor escalar</strong>. Este escalar, al que llamamos <strong>Pérdida</strong> (<em>Loss</em>), servirá como una medida global y objetiva del rendimiento del modelo en su estado actual.</p>
            
            <p>Para esta tarea, nuestro desarrollo matemático emplea una de las funciones de pérdida más fundamentales y extendidas en problemas de regresión: el <strong>Error Cuadrático Medio</strong> (<em>Mean Squared Error</em> o MSE). Se define de la siguiente manera:</p>
            
            \[ 
            \text{Loss} := \text{MSE} = \frac{1}{n} \sum_{a=1}^{a} \sum_{c=1}^{c} (Z_{ac} - Y_{ac})^2
            \]
            
            <p>Para comprender verdaderamente lo que esta ecuación representa, deconstruyámosla desde su núcleo hacia el exterior.</p>
            
            <ol>
                <li><strong>El Error Individual: \((Z_{ac} - Y_{ac})\)</strong><br>Todo comienza aquí, con la operación más simple: la diferencia entre el valor predicho \(Z_{ac}\) y el valor real \(Y_{ac}\) para una única muestra \(a\) y una única clase de salida \(c\). Este resultado, conocido como residuo, nos dice la magnitud y dirección del error para un único punto de predicción.</li>
                
                <br>
                
                <li><strong>El Error al Cuadrado: \((\dots)^2\)</strong><br>A continuación, elevamos esta diferencia al cuadrado. Este paso es crucial por dos razones. Primero, <strong>garantiza la positividad</strong>: al elevar al cuadrado, todos los errores (tanto si la predicción fue demasiado alta como demasiado baja) se convierten en valores positivos. Esto evita que errores de signo opuesto se anulen entre sí al sumarlos. Segundo, <strong>penaliza desproporcionadamente los errores grandes</strong>: un error de magnitud 2 contribuye con 4 a la pérdida total, mientras que un error de 10 contribuye con 100. Este comportamiento empuja al algoritmo de optimización a priorizar la corrección de las desviaciones más graves.</li>
                
                <br>
                
                <li><strong>La Suma Total: \(\sum_{a=1}^{a} \sum_{c=1}^{c}\)</strong><br>La doble sumatoria agrega todos estos errores cuadráticos individuales. <br><br> Mientras que la suma sobre las muestras \(a\) es intuitiva —simplemente estamos acumulando el error de cada una de las observaciones en nuestro conjunto de datos—, la suma sobre las clases \(c\) merece una atención especial.<br><br>Nuestro formalismo es general, diseñado para manejar modelos que pueden predecir múltiples valores simultáneamente (lo que se conoce como regresión multivariable). Imaginemos un caso en el que, para una entrada, predecimos tanto una altura como un ancho. Para esa única muestra, tendríamos un error en la predicción de la altura y otro en la del ancho. La función de pérdida debe consolidar estos errores en un único número que represente el rendimiento para esa muestra. La suma interna sobre \(c\) logra precisamente esto: <strong>agrega los errores cuadráticos de todas las dimensiones de salida para una muestra dada</strong>, dándonos el error total para esa única observación. Posteriormente, la suma externa sobre \(a\) acumula estos errores por muestra para obtener el error cuadrático total de todo el conjunto de datos.</li>
                
                <br>
                
                <li><strong>El Promedio: \(\frac{1}{n}\)</strong><br>Finalmente, dividimos la suma total por \(n\). Este término es una constante de normalización, donde \(n\) suele ser el número de muestras (\(a\)) o el número total de elementos (\(a \times c\)). Su propósito es hacer que el valor de la pérdida sea independiente del tamaño del lote de datos que estemos utilizando. Esto nos permite comparar de manera justa el rendimiento del modelo entre diferentes iteraciones o con diferentes conjuntos de datos.</li>
            </ol>
            
            <h3><strong>El Objetivo Final: Minimizar la Pérdida</strong></h3>
            
            <p>Es vital entender que el valor escalar del MSE no es simplemente una métrica de reporte. Es el <strong>objetivo central de nuestra optimización</strong>. Todo el proceso de entrenamiento se puede resumir en una sola meta: encontrar la combinación de parámetros en los tensores \(W\) y \(B\) que haga que el valor de esta función de pérdida sea lo más pequeño posible.</p>
            
            <p>Esto nos lleva a la pregunta que impulsa el resto de nuestro análisis: si tenemos un valor de pérdida, ¿cómo sabemos en qué dirección debemos ajustar los miles o millones de parámetros en \(W\) y \(B\) para reducirla? La respuesta no está en la intuición, sino en el cálculo diferencial. Necesitamos determinar la influencia de cada parámetro individual en el error total. Este es el propósito del <strong>Backward Pass</strong>.</p>
        
        <hr>

        <h2><strong>El Backward Pass: Rastreando la Influencia de Cada Parámetro</strong></h2>
            
            <p>Hemos cuantificado el error de nuestro modelo en un único escalar: la pérdida (MSE). Ahora nos enfrentamos a la pregunta central del aprendizaje: ¿cómo ajustamos los millones de parámetros en \(W\) y \(B\) para minimizar esta pérdida? La respuesta reside en el <strong>Backward Pass</strong>, un proceso elegante que utiliza el cálculo diferencial para determinar la contribución de cada parámetro individual al error total.</p>
            
            <p>El objetivo es calcular las derivadas parciales de la pérdida con respecto a cada elemento de nuestros tensores de parámetros. Estas derivadas, conocidas como gradientes, nos indicarán la dirección de máximo ascenso de la función de pérdida. Para minimizarla, simplemente daremos un pequeño paso en la dirección opuesta.</p>
            
            <p>Para mantener la consistencia dimensional, adoptaremos la <strong>convención de diseño del numerador</strong> (<em>numerator layout</em>). Esto significa que el resultado de una derivada tendrá dimensiones del numerador x denominador. Por ejemplo, el tensor de gradientes \(\frac{\partial Z}{\partial W}\) será un tensor de dimensiones \(a \times c \times b \times c \; \) ( \( a \times c \; \) son las dimensiones del tensor del numerador, y \( \; b \times c \; \) son las dimensiones del tensor del denominador).</p>
            
            <h3><strong>La Estrategia y una Aclaración Notacional Crucial</strong></h3>
            
            <p>Observando el diagrama de "Paths of Influence", vemos que los parámetros \(W\) y \(B\) no afectan la pérdida directamente. Su influencia es indirecta, mediada por el tensor de predicciones \(Z\). Esta estructura de dependencias nos obliga a usar la <strong>regla de la cadena</strong> del cálculo multivariable.</p>
            
            <p>Antes de aplicar la regla, debemos hacer una aclaración notacional fundamental. Al calcular la derivada de una función que contiene sumas (como el MSE o \(Z_{ac}\)) con respecto a un elemento específico de un tensor (por ejemplo, un peso particular), debemos distinguir entre los índices de la suma y los índices del elemento por el cual derivamos.</p>
            
            <ul>
                <li>Los índices dentro de una suma (\(a, b, c\)) son variables "mudas" o locales a esa suma.</li>
                
                <li>Los índices del elemento por el cual derivamos son "fijos" y definen una coordenada específica en el tensor de gradientes.</li>
            </ul>
            
            <p>Para evitar ambigüedad, usaremos un apóstrofe (') para los índices fijos. Así, calcularemos \(\frac{\partial \text{MSE}}{\partial W_{b'c'}}\) para encontrar el elemento en la fila \(b'\) y la columna \(c'\) del gradiente de los pesos.</p>

            <p>De todas formas, en ultima instancia, los indices con apoostrofe (') tienen los mismos valores que sus "gemelos".</p>

            
